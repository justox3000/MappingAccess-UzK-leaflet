#-------------Anpassen der UzK-Lageplandaten für das Projekt Mapping Access At UzK-------------#
# by Leonie Twente
# date: August 2019
# using datasets downloaded from Lageplan-DB provided by the RRZK (Herr Holz)
#-----------------------------------------------------------------------------------------
  #this script imports csv data that was generated by exporting tables from the Lageplan
  #Database at RRZK Uni Köln
  #it cleans the dataset, removes and adds columns for modelling the dataframes to be used
  #in the accessability map of Mapping Access At UzK
  #the output will be csv which will then be converted to geojson in qgis.
  #finally, more data will be added to the map via APIs such as accessability cloud.

  #also there should be an opportunity for people to add data by filling in
  #prepared spreadsheets that have the outline of the final dataframe. --> TODO as function
  #to download the spreadsheets or fields to fill in data.


#Steps to Take for Modelling the Datasets for Mapping Access At UzK - leaflet
  #import csv one by one
  #make dataframes, manipulate column names and delete columns deemed unnecessary
  #then merge dataframes about buildings to represent buildings with information in one dataframe
  #this is the base material to which we add new info about accessability


#model the columns and representations needed for Mapping Access At UzK
#represent them in the dataframes, adding columns with space for accessability data

#export final dataframes as csv and import to qgis.
#convert to geojson in qgis

#use in leaflet application in nodejs/npm


#-----------------------------------------------------------------------------------------


##########################STEP 0: Installations and settings ##########################

#preliminaries
stringsAsFactors = FALSE;#important setting for importing data
#install.packages(dplyr) # install dplyr package
require(dplyr)#require dplyr package

getwd() #check if current directory points to MappingAccessAtUzK-Utilities

current_folder <- "./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/"
list.files(current_folder)


##########################STEP 1: create dataframes from import##########################

#Dataframes einlesen aus csv-Dateien

#Data from RRZK: in total, there are 8 tables in the database

#the following three datasets serve to hold data on:Gebäude (Polygone), Parking, "Familiencampus"
#(in Zukunft ergänzen durch weitere infos, z. B. Unisport, Öffentlicher Nahverkehr etc.)


  #Parking contains 48 rows of data, including lat and long data in columns 2 and 3
  #it codes if parking is public, belongs to the uni or clinic (column 4: values 0-2)
  #primary key id in column 1
  #dies soll zunächst unabhängig von Unigebäuden abgebildet werden

  #Markers contains 84 rows of data, including lat and long data in columns 2 and 3
  #it codes information from the family centre of the university; type (column 5 contains values: 0-4
  # for different info such as Wickeltisch or Unisextoilette) -> unisex is seperated out
  # we have no other toilet location data
  #it is unclear what "layer" column 4 contains (values 0,1) --> is kept but ignored
  # primary key id in column 1

  #gebaude_polygons contains 307 rows of data, including georeferencing in polyline encoded format
  #other than that it contains a column
  #primary key id in column 1
  #polygons might be displayed without entry data, depending on other kind of info available.
  #and  they might serve as a basemap.

  #Parking Dataframe
  parking <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_parking.csv", header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(parking)
  summary(parking)

  #family-Campus Dataframe
  family_campus <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_markers.csv", header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(family_campus)
  summary(family_campus)

  #uni_building_polygons Dataframe
  uni_building_polygons <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_gebaude_polygons.csv", header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(uni_building_polygons)
  summary(uni_building_polygons)



#the following datasets contain some data that will be deleted or modified
#it constitutes mainly of feature-data belonging to a certain information type, e.g. gebaude_polygons
#(see foreign keys in database)

  #gebaude_entries contains 226 rows of data, including lat-lng data in columns 3 and 4
  #it codes information about entries to the buildings and if they are wheelchair accessible
  #which is coded binary in 0 = entry, 1=wheelchair accessible in column 5
  #primary key id in column 1
  #since it wont be of much use to show entries alone, they will always be displayed with the polygon data and thus e an accessability feature

  #gebaude/uni_building_data contains 307 rows of data but no lat-lng data.
  #it codes info about the different buildings, including Gebäudenummer (Fremdschlüssel),
  #Strasse (Fremdschlüssel), Hausnummer, Plz, Ort und Name des Gebäudes sowie die Zugehörigkeit
  #zur Uni (0), zur Klinik (1), extern (3). Bildpfade sind angegeben, aber nicht verfügbar.
  #ein solches Feld sollte aber mitgedacht werden!
  #weitere Angaben können gelöscht werden
  #primary key is id in column 1

  #einrichtungen contains 1404 rows of data but no lat-lng data
  #it codes name, Tel.nr. Fax, Hmepage, Gebäude, Gebäudenummer, Fakultät, zugehörige Einrichtungen und Mail der
  #Einrichtungen. Weitere Spalten enthalten Metadaten für den Server (z. B. Statusangaben)
  #column "Institutskuerzel" heißt in anderen Tabellen "einrichtung" (?), beinhaltet den Einrichtungscode.
  #institutskuerzel und gebaudenummer sind je ein Fremdschlüssel

  #einrichtungshierarchie contains 965 rows of data but no lat-lng data
  #it codes relationships between institutions/einrichtungen
  #parent, child, reihenfolge, hierarlvl (Hierarchielevel)
  #parent und child columns sind zusammen der primary key

  #aliase contains 215 rows of data but no lat-lng data
  #it codes Alias names for institutes and buildings.
  #Aliaskuerzel und Institutskuerzel sind zusammen der Fremdschlüssel
  #Aliasname ??


  #uni_building_entries Dataframe
  uni_building_entries <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_gebaude_entries.csv", header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(uni_building_entries)
  summary(uni_building_entries)

  #uni_building_data Dataframe
  uni_building_data <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_gebaude.csv" , header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(uni_building_data)
  summary(uni_building_data)

  #einrichtungen Dataframe
  einrichtungen <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_Einrichtungen.csv" , header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(einrichtungen)
  summary(einrichtungen)

  #einrichtungshierarchie Dataframe
  einrichtungshierarchie <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_Einrichtungshierarchie.csv" , header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(einrichtungshierarchie)
  summary(einrichtungshierarchie)

  #aliase Dataframe
  aliase <- read.csv("./original_data/20190812_original_rrzk_lageplan_export/lageplan-separate-tables-csv/lageplan_table_Aliase.csv" ,header = FALSE, sep=",", quote="\"", fileEncoding="utf-8")
  #View(aliase)
  summary(aliase) #over#View over content of dataframe


##########################STEP 2: Assignment of Column Names##########################

#Column Names rekonstruieren auf Basis der Spaltennamen in der Lageplan-Datenbank-Tabelle

#Vergleichstabelle öffnen:

#file.show("./original_data/20190812_original_rrzk_lageplan_export/uebersicht_tabellenspalten.xlsx")

#Assign Column Names to parking Dataframe
  #v1 = id, v2 = lat, v3 = lng, v4 = type (0=Uni, 1 = Uni-angehörig, 2= Klinik)
  colnames(parking) <- c("id", "lat", "lng", "type_of_parking") #set colnames
  colnames(parking) #get colnames
  #View(parking)


#Assign Column Names to family_campus Dataframe
  #v1 = id, v2 = lat, v3 = lng, v4 = layer (0, 1 unclear meaning)
  #v5 = type (0=Wickelraum, 1 = Stillraum, 2= Eltern-Kind-Raum, 3= Kita, 4=Spielplatz, 5=unisextoiletten)
  colnames(family_campus) <- c("id", "lat", "lng", "layer", "type_of_family_campus") #set colnames
  colnames(family_campus) #get colnames
  #View(family_campus)


#Assign Column Names to uni_building_polygons Dataframe
  #v1 = id, v2 = polygons_gebaude_id, v3 = polyline (polyline encoded mbstring for polygon georef data)
  colnames(uni_building_polygons) <- c("id", "polygons_gebaude_id", "polyline") #set colnames
  colnames(uni_building_polygons) #get colnames
  #View(uni_building_polygons)


#Assign Column Names to uni_building_entries Dataframe
  #v1 = id, v2 = entries_gebaude_id, v3 = lat, v4 = lng, var5 = accessability (0 nonaccessible, 1 accessible entry - unclear what kind of info that refers to)
  colnames(uni_building_entries) <- c("id", "entries_gebaude_id", "lat", "lng", "entries_bin_accessability") #set colnames
  colnames(uni_building_entries) #get colnames
  #View(uni_building_entries)


#Assign Column Names to uni_building_data Dataframe
  #v1 = id, v2 = gebaudenummer, v3 = strasse (v2 und v3 sind zusammen ein fremdschlüssel), "dummy", "zugehoerigkeit", "liste", "praefix_x", "temp", "markierung_x", "markierung_y", bereich_x1", "bereich_x2", "bereich_y1", "bereich_y2", "stadtplanlink"
  colnames(uni_building_data) <- c("id", "nummer", "strasse", "hausnummer", "plz", "ort", "bild", "name_gebaude", "dummy", "zugehoerigkeit", "liste", "praefix_x", "etagenplan", "temp", "markierung_x", "markierung_y", "bereich_x1", "bereich_x2", "bereich_y1", "bereich_y2", "stadtplanlink" ) #set colnames
  colnames(uni_building_data) #get colnames
  #View(uni_building_data)

#Assign Column Names to einrichtungen Dataframe
  #v1 = id, v2=institutskuerzel ("einrichtung"/fremdschlüssel; beinhaltet einrichtungscode), name (einrichtungsname)
  #v4=kurzname, v5=telefonnummmer, v6=fax, v7=homepage, v8=gebaudenummer (Fremdschlüssel)
  #v9=Geschoss, v10=Gebzusatz, var11=Bit1, var12=Bit2, var13=Bit3, var14=Bit4, var15=Bit5, v16=mail
  #var17=wwwpfad, var18=kommentar, var19=artserver, var20=afsnomral, var21=afsadmin, var22=fakultaet
  #var23=andereeinrichtung, var24=Status
  colnames(einrichtungen) <- c("id","institutskuerzel", "name","kurzname", "telefonnummer", "fax", "homepage", "gebaudenummer", "geschoss", "gebzusatz", "bit1", "bit2", "bit3", "bit4", "bit5", "mail", "wwwpfad", "kommentar", "artserver", "afsnormal", "afsadmin", "fakultaet", "andereeinrichtung", "status") #set colnames
  colnames(einrichtungen) #get colnames
  #View(einrichtungen)


#Assign Column Names to  einrichtungshierarchie Dataframe
  #v1=parent (zusammen mit child primary key), v2=child (zsm. mit parent primary key), v3=reihenfolge, v4=hierarlvl (Hierarchielevel)
  colnames(einrichtungshierarchie) <- c("parent", "child", "reihenfolge", "hierarlvl") #set colnames
  colnames(einrichtungshierarchie) #get colnames
  #View(einrichtungshierarchie)

#Assign Column Names to aliase Dataframe
  #v1 = id, v2=Aliaskürzel (Fremdschlüssel zsm. mit Institutsschlüssel var4), var3=Aliasname, var4=Institutskuerzel (zsm. mit Aliaskuerzel Fremdschlüssel)
  colnames(aliase) <- c("id", "aliaskuerzel", "aliasname", "institutskuerzel") #set colnames
  colnames(aliase) #get colnames
  #View(aliase)



##########################STEP 3: Manipulate dataframes to create the data model needed for Mapping Access At UzK ##########################

#create  dataframe "toilets" and remove "unisex toilets" from family_campus  dataframe

library(dplyr)
#make dataframe "toilets" (for now we only have unisex toilet datapoints)
  #unisex will be a feature in the accessability feature set)

  #thus filter only the unisex toilets from family_campus into dataframe toilets
toilets <- family_campus %>% filter(type_of_family_campus == 5)


#create column "unisex" which will take values 0, 1 to code if unisex or not

names(toilets)[names(toilets)=="type_of_family_campus"] <- "unisex" #rename column

toilets$unisex  <- rep("1", nrow(toilets)) #as all toilets from lageplan are unisex, fill all  with 1 (true)



#remove rows with type_of_family_campus == 5 on  dataframe "family_campus"

family_campus <- subset(family_campus, type_of_family_campus !=5)
#View(family_campus$type_of_family_campus) # now has no more type_of_family_campus unisex info


#dataframes with lat-lng data: family-campus (family locations), parking (parking opportunities), toilets (toilets on campus)
  #uni_building_polygons (buildings on campus and the institutions they host; polygons_gebaude_id maps onto uni_building_data$id)

  str(family_campus)
  str(parking)
  str(toilets)
  str(uni_building_polygons)

#dataframes with lat-lng data to be accessability feature data: uni_building_entries (uni_building_entries$entries_gebaude_id maps onto uni_building_data$id)
  str(uni_building_entries)

#dataframes without lat-lng data to be accessability features, that need their rows be matched to the corresponding lat-lng information:
  #uni_building_data (Adresse, Gebäudenummer, Bild, Gebäudename, Etagenplan, Zugehörigkeit des Gebäudes)
  #einrichtungen (Name, Fakultät, Internetadresse, Mail/Kontakt, Gebäudezusatz, Geschoss, einrichtungen$gebaudenummer maps onto uni_building_data$nummer)

  str(uni_building_data)
  str(einrichtungen)

#identified relevant datasets that need removal of unnecessary columns:
colnames(einrichtungen)

einrichtungen$institutskuerzel <- NULL
einrichtungen$bit1 <- NULL
einrichtungen$bit2<- NULL
einrichtungen$bit3<- NULL
einrichtungen$bit4<- NULL
einrichtungen$bit5<- NULL
einrichtungen$kommentar <- NULL
einrichtungen$artserver <- NULL
einrichtungen$afsnormal<- NULL
einrichtungen$afsadmin<- NULL
einrichtungen$andereeinrichtung<- NULL
einrichtungen$status<- NULL

colnames(einrichtungen) #11 variables left: id, name, contact data, numbe rof building, floor, web address, faculty

str(uni_building_data)
uni_building_data$dummy<- NULL
uni_building_data$etagenplan<- NULL
uni_building_data$liste<- NULL
uni_building_data$praefix_x<- NULL
uni_building_data$temp<- NULL
uni_building_data$markierung_x<- NULL
uni_building_data$markierung_y<- NULL
uni_building_data$bereich_x1<- NULL
uni_building_data$bereich_x2<- NULL
uni_building_data$bereich_y1<- NULL
uni_building_data$bereich_y2<- NULL
uni_building_data$stadtplanlink<- NULL

colnames(uni_building_data)#10 variables left: id, nummer, strasse, hausnummer, plz, ort, bild, name_gebaude, zgehörigkeit, etagenplan


#dataframes identified as irrelevant: aliase, einrichtungshierarchie. save in case needed as csv and txt
write.table(aliase, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/ignored/20190816_aliase_manipulated.txt", quote = FALSE, sep = "\t", row.names = FALSE, fileEncoding = "utf-8")
write.table(aliase, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/ignored/20190816_aliase_manipulated.csv", quote=FALSE, sep="$", row.names = FALSE, fileEncoding="utf-8")

write.table(einrichtungshierarchie, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/lageplan_matuzk_csvTxtFiles/ignored/20190816_einrichtungshierarchie_manipulated.txt", quote = FALSE, sep = "\t", fileEncoding = "utf-8")
write.table(einrichtungshierarchie, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/ignored/20190816_einrichtungshierarchie_manipulated.csv", quote=FALSE,  sep="$", row.names = FALSE, fileEncoding="utf-8")


#merge datasets so that we have one dataset on georeferenced buildings and the institutions they host
#(based on uni_building_polygons)


#rename all the ids for the relevant datasets
uni_building_data <- rename(uni_building_data, gebaude_id = id)
aliase <- rename(aliase, aliase_id =id)
einrichtungen <- rename(einrichtungen, einrichtungen_id = id)
family_campus <- rename(family_campus, fc_id=id)
parking <- rename(parking, parking_id = id)
toilets <- rename(toilets, toilet_id = id)
uni_building_entries <- rename(uni_building_entries, entries_id = id)
uni_building_polygons <- rename(uni_building_polygons, polygon_id = id)


#rename columns uni_building_entries dataset:
uni_building_entries <- rename(uni_building_entries, entries_lat = lat, entries_lng = lng)
colnames(uni_building_entries)


#You can merge function to combine the two dataframe in R.
#This function is available in base package and using merge function one can get the inner, outer, left, right and cross joins.

#merge uni_building_data, einrichtungen and uni_building_entries with uni_building_polygons to join data with lat lng data (whilst preserving lat lng points for the Uni_building_entry data rows)
summary(uni_building_data)
dim(uni_building_data)#307 rows, 10 variables
summary(uni_building_polygons)
dim(uni_building_polygons) #307 rows, 3 variables
summary(uni_building_entries)
dim(uni_building_entries) #226 rows, 5 variables


#1. einrichtungen_building_data <- merge uni_building_data with einrichtungen via gebaudenummer
#some einrichtungen have gebaudenummer NULL (N=280) or no building matched.
#thus some institutions do not have a matched location/building.
#do a full outer join: all=TRUE

einrichtungen_building_data <- merge(einrichtungen, uni_building_data, by.x="gebaudenummer", by.y="nummer", all=TRUE)
colnames(einrichtungen_building_data)
summary(einrichtungen_building_data)

#2. poly_geb_einrich <- merge uni_building_polygons with einrichtungen_building_data via gebaude_id
#no missing values in uni_building_polygons but as some einrichtungen do not have building data, rows need to be filled with "NULL" for the columns of uni_building_polygons
poly_geb_einrich <- merge(uni_building_polygons, einrichtungen_building_data, by.x="polygons_gebaude_id", by.y="gebaude_id", all=TRUE)
colnames(poly_geb_einrich)
summary(poly_geb_einrich)

#3. optional::both a file containing building data and entry data is produced as well as both datasets seperately in files

#uzk_buildings_including_entries <- merge  uni_building_entries with ply_geb_einr via gebaude_id
#no missing values in uni_building_entries
uzk_buildings_including_entries <- merge(uni_building_entries, poly_geb_einrich, by.x="entries_gebaude_id", by.y="polygons_gebaude_id", all=TRUE)
colnames(uzk_buildings_including_entries)
summary(uzk_buildings_including_entries)
View(uzk_buildings_including_entries)

#rename columns to establish readable dataset

uzk_buildings_including_entries <- uzk_buildings_including_entries %>%
  rename(building_id=entries_gebaude_id,
         entry_id=entries_id ,
         entry_lat=entries_lat,
         entry_lng=entries_lng,
         entry_bin_accessability = entries_bin_accessability,
         building_polygon_id = polygon_id,
         building_polyline = polyline,
         building_number = gebaudenummer,
         institution_id=einrichtungen_id,
         institution_name = name,
         institution_shortname = kurzname,
         institution_tel=telefonnummer,
         institution_fax = fax,
         institution_homepage = homepage,
         institution_floor=geschoss,
         institution_buildingspecification=gebzusatz,
         institution_mail = mail,
         institution_wwwpath= wwwpfad,
         institution_faculty=fakultaet,
         building_street=strasse,
         building_housenr = hausnummer,
         building_postalcode=plz,
         building_city=ort,
         building_image=bild,
         building_name=name_gebaude,
         building_affiliation=zugehoerigkeit,
        )

colnames(uzk_buildings_including_entries)

#building_id ist die ID für das Gebäude
#building_polygon_id ist die ID für die Polyline eines Gebäudes
#building_polyline ist die Polyline georef des Gebäudes
#building_number ist die Nummer des Gebäudes
#building_name ist der Name des Gebäudes
#building_street
#building_housenr
#building_postalcode
#building_city
#building_image specifies the path to an image
#building_affiliation ist die Zugehörigkeit des Gebäudes zur Uni, Klinik oder extern

#institution_id ID der Einrichtung
#institution_name
#institution_shortname
#institution_tel
#institution_fax
#institution_homepage spezifiziert den Internetauftritt
#institution_floor spezifiziert die Etage
#institution_buildingspecification spezifiziert den Gebäudeteil o.ä.
#institution_mail spezifiziert die Emailaddresse der Institution
#institution_wwwpath spezifiziert einen Pfad der Internetadresse
#institution_faculty ist die Fakultätszugehörigkeit


#entry_id ist die ID des Eingangs zu einem Gebäude
#entry_lat ist die Georef des Eingangs (latitude)
#entry_lng ist die Georef des Eingans (longitude)
#entry_bin_accessability spezifiziert ob der Eingang zugänglich oder nicht zugänglich ist (binary)


#set order of columns


col_order <- c("building_id", "building_polygon_id", "building_polyline", "building_number", "building_name", "building_street", "building_housenr",
               "building_postalcode", "building_city", "building_image", "building_affiliation", "institution_id", "institution_name", "institution_shortname",
               "institution_tel", "institution_fax", "institution_homepage", "institution_floor", "institution_buildingspecification", "institution_mail",
               "institution_wwwpath", "institution_faculty",
               "entry_id", "entry_lat", "entry_lng", "entry_bin_accessability")

uzk_buildings_including_entries<- uzk_buildings_including_entries[, col_order]
colnames(uzk_buildings_including_entries)

#save the resulting dataframe to disk as csv and txt
write.table(uzk_buildings_including_entries, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_incl_entries_total.txt", quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")
write.table(uzk_buildings_including_entries, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_incl_entries_total.csv", quote=FALSE,  sep="$", row.names = FALSE, fileEncoding="utf-8")

#remove all data that does not have georef (295 NA values in uzk_buildings_including_entries$building_polyline)
dim(uzk_buildings_including_entries)

uzk_buildings_incl_entries_georef <- subset(uzk_buildings_including_entries, !is.na(building_polyline))

dim(uzk_buildings_incl_entries_georef)
uzk_buildings_incl_entries_georef

write.table(uzk_buildings_incl_entries_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_incl_entries_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_buildings_incl_entries_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_incl_entries_georef.csv", quote=FALSE, sep="$", row.names = FALSE, fileEncoding="utf-8")


#uzk_buildings_inlc_entries ist jetzt ein fertiges plain dataset, das mit accessability features aus dem Datenmodell angereichert wird.

#repeat for buildings without entry data


uzk_buildings <- poly_geb_einrich %>%
  rename(building_id=polygons_gebaude_id,
         building_polygon_id = polygon_id,
         building_polyline = polyline,
         building_number = gebaudenummer,
         institution_id=einrichtungen_id,
         institution_name = name,
         institution_shortname = kurzname,
         institution_tel=telefonnummer,
         institution_fax = fax,
         institution_homepage = homepage,
         institution_floor=geschoss,
         institution_buildingspecification=gebzusatz,
         institution_mail = mail,
         institution_wwwpath= wwwpfad,
         institution_faculty=fakultaet,
         building_street=strasse,
         building_housenr = hausnummer,
         building_postalcode=plz,
         building_city=ort,
         building_image=bild,
         building_name=name_gebaude,
         building_affiliation=zugehoerigkeit,
  )



col_order_buildings<- c("building_id", "building_polygon_id", "building_polyline", "building_number", "building_name", "building_street", "building_housenr",
               "building_postalcode", "building_city", "building_image", "building_affiliation", "institution_id", "institution_name", "institution_shortname",
               "institution_tel", "institution_fax", "institution_homepage", "institution_floor", "institution_buildingspecification", "institution_mail",
               "institution_wwwpath", "institution_faculty")

uzk_buildings<- uzk_buildings[, col_order_buildings]
colnames(uzk_buildings)

uzk_buildings_georef <- subset(uzk_buildings, !is.na(building_polyline))

write.table(uzk_buildings_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_buildings_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_buildings_georef.csv", quote=FALSE, sep="$", row.names = FALSE, fileEncoding="utf-8")
View(uzk_buildings_georef)

#make institution dataset containing only those matched to a building and the corresponding building_id
#uzk_institutions_georef <- select(uzk_buildings_georef, -
uzk_institutions_georef <- uzk_buildings_georef[, -c(2:10)] # delete columns 5 through 7
View(uzk_institutions_georef)
uzk_institutions_georef$building_affiliation <- NULL
View(uzk_institutions_georef)

write.table(uzk_institutions_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_institutions_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_institutions_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_institutions_georef.csv", quote=FALSE, sep="$", row.names = FALSE, fileEncoding="utf-8")
dim(uzk_institutions_georef)

#make uzk_only_building_georef containing only cleaned building data
dim(uzk_buildings_georef)
uzk_only_buildings_georef <- select(uzk_buildings_georef, -starts_with("insti"))
dim(uzk_only_buildings_georef)
#deduplicate rows of buildings via building_id
uzk_only_buildings_georef <- unique(uzk_only_buildings_georef)
dim(uzk_only_buildings_georef)
View(uzk_only_buildings_georef)
write.table(uzk_only_buildings_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_only_buildings_dedup_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_only_buildings_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_only_buildings_dedup_georef.csv", quote=FALSE, sep="$", row.names = FALSE, fileEncoding="utf-8")


#repeat for preparing  entries, parking, toilets, family_campus
uzk_building_entries <- uni_building_entries
uzk_parking <- parking
uzk_toilets <- toilets
uzk_family_campus <- family_campus


uzk_toilets$layer <- NULL #delete layer column as it is not needed
uzk_family_campus$layer <- NULL#delete layer column as it is not needed


#rename columns and reorder column order


uzk_building_entries_georef <- uzk_building_entries %>%
  rename(entries_id=entries_id,
         entries_lat=entries_lat,
         entries_lng=entries_lng,
         entries_bin_accessability=entries_bin_accessability)
uzk_building_entries_georef

uzk_parking_georef <- uzk_parking %>%
  rename(parking_id=parking_id,
         parking_lat=lat,
         parking_lng=lng,
         parking_affiliation= type_of_parking)
uzk_parking_georef

uzk_toilets_georef <- uzk_toilets %>%
  rename(toilet_id = toilet_id,
         toilet_lat=lat,
         toilet_lng=lng,
         toilet_is_unisex=unisex,
         )
uzk_toilets_georef

uzk_family_campus_georef <- uzk_family_campus %>%
  rename(fc_facility_id = fc_id,
         fc_lat=lat,
         fc_lng=lng,
         fc_facility_type= type_of_family_campus)
uzk_family_campus_georef


#all the dataframes that contain all data to disk as csv and txt


write.table(uzk_building_entries_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_building_entries_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_building_entries_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_building_entries_georef.csv", quote=FALSE,  sep="$", row.names = FALSE, fileEncoding="utf-8")


write.table(uzk_parking_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_parking_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_parking_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_parking_georef.csv", quote=FALSE,  sep="$", row.names = FALSE, fileEncoding="utf-8")


write.table(uzk_parking_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_parking_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_parking_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_parking_georef.csv", quote=FALSE,  sep="$", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_toilets_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_toilets_georef.txt",  quote=FALSE, sep="\t",row.names = FALSE,  fileEncoding="utf-8")

write.table(uzk_toilets_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_toilets_georef.csv", quote=FALSE, sep="$", row.names = FALSE,
            fileEncoding="utf-8")

write.table(uzk_family_campus_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_family_campus_georef.txt",  quote=FALSE, sep="\t", row.names = FALSE, fileEncoding="utf-8")

write.table(uzk_family_campus_georef, file="./cleaned_data/lageplan_matuzk_csvTxtFiles/20190816uzk_family_campus_georef.csv", quote=FALSE,  sep="$", row.names = FALSE,
            fileEncoding="utf-8")


##########################STEP 4: add modelled data for accessability features (script: custom_A11JSON.R##########################
